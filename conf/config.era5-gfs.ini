[SHARE]

# ntasks for IO, 8 would be enough to occupy full bandwidth 
ntasks=4

# spatial selection for Outter Domain
# downsampling interval, 1 for all grids, 2 for each every two grids
dsmp_interval=3 
# start/end lat/lon for S-N/W-E direction
s_sn=10
e_sn=60
s_we=60
e_we=170

[TRAINING]
# source path to ERA5 reanalysis
era5_src=/home/metctm1/array/workspace/Prism/input/era5-training

# training date range, in whole month
training_start=20100101
training_end=20201231

# subset hour list, 6-hourly freq, 
# for example: 0  0,12  0,6,12,18 
# -1 for all (0, 6, 12, 18)
sub_hrs=0

# sub month list, for example: 12,1,2  6,7,8  -1 for all months
sub_mons=-1

# 2-D clustering node numbers
# for example, 8 types could be assigned as 1x8 or 2x4
# let the smaller number be the row idx n_nodex
# if n_nodex=1, the topological structure would be 1-D
n_nodex=1
n_nodey=8

# Spread of the neighbourhood function, needs to be adequate to the dimensions of the map.
sigma=0.01
# initial learning rate
learning_rate=0.01
# neighbourhood function
nb_func= gaussian 

iterations=10000

# preprocessing options: 
# temporal_norm (single or multiple variables)
# original (single variable)
preprocess_method=temporal_norm

# use grid search to get optimal hyper-parameters
grid_search_opt=True


[INFERENCE]
# debug mode for small sample tests 
debug_mode=False

# Set True to download reatime GFS data 
down_realtime_gfs=True

# GFS source path
gfs_src=/home/metctm1/array/workspace/Prism/input/gfs-inference/

# offset day for realtime forecast relinkage, 
# 1 for yesterday, 2 for the day before yesterday
realtime_offsetday=0

# GFS initial time: 00, 06, 12, 18
gfs_init=00

# requested GFS output frq: 1,2,3,6,12 or 24
gfs_frq=3

# GFS forecast days
gfs_days=7

# output resample freq, e.g. 1H, 3H, 6H, D
# see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases
resamp_freq=3H

# flag for matching history
match_hist=False


[GRID_SEARCH]

# how many processors for grid search, as
# individual grid search is a standalone task
# user could set nworkers as many as the machine
# provides to expoilt parallelism
gs_nworkers=4

# Spread of the neighbourhood function
# format: 0.1, 0.3, 0.5
gs_sigma=0.1, 0.3
gs_learning_rate= 0.01
#gs_learning_rate=0.005, 0.01, 0.05
#gs_learning_rate=0.01, 0.05

# set 2-D topology of SOM nodes
#gs_nodexy=1x8,2x4,1x9,3x3,1x10,2x5
gs_nodexy=1x8,2x4

# suggest >=2000 for Gaussian, >=10000 for mexican hat
gs_iterations=10000

# ONLY gaussian available (Aug 7, 2021)
# If use mexican_hat, please 0.1x sigma and learning_rate for gaussian
gs_nb_func= gaussian

[OUTPUT]
output_root = ./output/

